# 50 LLM Building and fine-tuning

This document provides **reusable prompts** for each major subtopic related to AI Agents, with definitions only for concepts unlikely to become outdated. New subtopics are suggested where relevant, supporting concise and future-proof learning[1].


- Recall Oriented Understudy for Gisting Evaluation, or ROUGE, is a set of metrics and a software package. It is used to evaluate automatic summarization tasks and machine translation software in natural language processing
- Bilingual Evaluation Understudy, or BLEU, is an algorithm that is used for translation tasks
- General Language Understanding Evaluation, GLUE, Holistic Evaluation of Language Models,
- HELM, Massive Multitask Language Understanding, MMLU, and Beyond the Imitation Game Benchmark, BIG-bench.
- Massive Multitask Language Understanding, MMLU, evaluates the knowledge and problem-solving capabilities of the model
- difference between pre-training and fine-tuning
  - pre-training, you train the LLM by using huge amounts of unstructured data with self-supervised learning.
  - fine-tuning, supervised learning process and you use a dataset of labeled examples to update the weights of the LLM
